---
title: "Assign3"
format: html
---

# Setup

Some packages:
```{r}
#| label: packages
#| collapse: TRUE
library(dplyr)
library(tidyr)
library(ggplot2)
library(patchwork)
set_theme(theme_bw()) # for ggplot formatting
```

Now the data:
```{r}
#| label: load-data
#| collapse: TRUE
anpp <- read.csv('global_ANPP_data.csv', header = TRUE) |>
  select(-X) # get rid of "X" column that's an artifact of the file
str(anpp)
anpp$region <- as.factor(anpp$region)
table(anpp$region)

anpp_f <- filter(anpp, region != 'AF') # filter out AF for low sample size
```

AF only has 3 observations; if we include region as a factor, we should exclude these data because there just aren't enough to make robust inference.

# EDA: variable distributions -- Q1 and 2

## Histograms

> note for Noah: the #| lines at the beginning of chunks aren't R code -- they're options for Quarto in knitting and evaluating chunks. #| label: xxxx means label this chunk xxxx for organization/future reference.

A histogram plotting function to avoid a ton of redundant code:

```{r}
#| label: plot-hist
# We use {{var}} so we can use dplyr-style data masking: from Hadley Wickham
#> "programming with dplyr" page

plot_hist <- function(data, 
                      var,
                      rgn = FALSE, 
                      color = 'grey20',
                      fill = 'lightgrey',
                      fill_alpha = 0.75,
                      num_bins = 10,
                      add_mean = TRUE,
                      line_col = 'red',
                      line_type = 'dashed'){
  p <- ggplot(data)
  
  # First, construct histograms either with fill by region or not
  if(rgn == FALSE){
    p <- p+geom_histogram(aes(x = {{var}}),
                            color = color,
                            fill = fill,
                            bins = num_bins)+
      labs(y = 'Count')
  }else{
    p <- p+geom_histogram(aes(x = {{var}},
                              fill = region),
                            alpha = fill_alpha,
                            color = color,
                            bins = num_bins)+
      labs(y = 'Count',
           fill = 'Region')
  }

  if(add_mean == TRUE){
    p <- p+geom_vline(aes(xintercept = mean({{var}})),
                      color = line_col,
                      linetype = line_type)
  }   
  
  return(p)
}
```


And now let's use the code to make some histograms.

```{r}
#| label: histograms
#| 

# MAT
## Overall
mat_hist <- plot_hist(data = anpp,
                      var = MAT)

## by region
mat_hist_rgn <- plot_hist(data = anpp_f,
                          var = MAT,
                          rgn = TRUE)

# MAP
## Overall
map_hist <- plot_hist(data = anpp,
                      var = MAP)

## by region
map_hist_rgn <- plot_hist(data = anpp_f,
                          var = MAP,
                          rgn = TRUE)

# ANPP
## Overall
anpp_hist <- plot_hist(data = anpp,
                       var = ANPP)

## by region
anpp_hist_rgn <- plot_hist(data = anpp_f,
                           var = ANPP,
                           rgn = TRUE)

# Now make a figure:
## Overall
mat_hist+map_hist+anpp_hist+plot_layout(axis_titles = 'collect')

## By region
mat_hist_rgn+map_hist_rgn+anpp_hist_rgn+plot_layout(axis_titles = 'collect',
                                                    guides = 'collect')
```


## Scatterplots

Again, a function to save typing. Since we're going to be using a gamma distribution with a log link, let's examine linearity of predictors WRT log(ANPP) (though this behavior is customizable with the `yvar` option).

```{r}
plot_scatter <- function(data,
                         xvar,
                         yvar = log(ANPP),
                         rgn = FALSE,
                         pt_alpha = 0.5,
                         smooths = 'global',
                         smooth_col = 'blue',
                         smooth_lty = 'dashed',
                         smooth_lty_rgn = 'solid'){
  # fail fast
  stopifnot(smooths %in% c('all', 'global', 'region', 'none'))
  
  # plot template
  p <- ggplot(data, aes(x = {{xvar}}, y = {{yvar}}))

  if(rgn == FALSE){
    p <- p+geom_point(alpha = pt_alpha)
  }else{
    p <- p+geom_point(aes(color = region), alpha = pt_alpha)+
      labs(color = 'Region')
  }
    
  if(smooths == 'global'){
    p <- p+geom_smooth(inherit.aes = FALSE,
                       aes(x = {{xvar}},
                           y = {{yvar}}),
                         formula = y ~ x,
                         method = 'loess',
                         se = FALSE,
                         col = smooth_col,
                         linetype = smooth_lty)
    }else if(smooths == 'region'){
      p <- p+geom_smooth(se = FALSE,
                         formula = y ~ x,
                         method = 'loess',
                         linetype = smooth_lty_rgn)
    }else if(smooths == 'all'){
      p <- p+geom_smooth(aes(color = region),
                    se = FALSE,
                         formula = y ~ x,
                         method = 'loess',
                         linetype = smooth_lty_rgn)+
        geom_smooth(inherit.aes = FALSE,
                       aes(x = {{xvar}},
                           y = {{yvar}}),
                         formula = y ~ x,
                         method = 'loess',
                         se = FALSE,
                         col = smooth_col,
                         linetype = smooth_lty)
        
    }else{
      message('no smooths added')
    }
  
  return(p)
}
```

Using that function:

```{r}
#| label: scatterplots

# MAT
## Overall
mat_scatter <- plot_scatter(anpp, xvar = MAT, smooth_lty = 'solid')

## Regional
mat_scatter_rgn <- plot_scatter(anpp_f, 
                                xvar = MAT, 
                                rgn = TRUE, 
                                smooths = 'all',
                                smooth_col = 'black')


# MAP
## Overall
map_scatter <- plot_scatter(anpp, xvar = MAP, smooth_lty = 'solid')

## Regional
map_scatter_rgn <- plot_scatter(anpp_f, 
                                xvar = MAP, 
                                rgn = TRUE, 
                                smooths = 'all',
                                smooth_col = 'black')


# Log MAP
## Overall
log_map_scatter <- plot_scatter(anpp, xvar = log(MAP), smooth_lty = 'solid')

## Regional
log_map_scatter_rgn <- plot_scatter(anpp_f, 
                                xvar = log(MAP), 
                                rgn = TRUE, 
                                smooths = 'all',
                                smooth_col = 'black')

# Figures
## Overall
map_scatter+mat_scatter+plot_layout(axis_titles = 'collect') 

## Regional
map_scatter_rgn+mat_scatter_rgn+plot_layout(axis_titles = 'collect',
                                            guides = 'collect')

## Log vs untransformed
map_scatter+log_map_scatter+plot_layout(axis_titles = 'collect')

```


## Takeaways (Q3)

We can see a few things here:

1. ANPP is positive, continuous, and skewed (from the histogram)
2. ANPP variance is not constant with respect to MAT (from the scatterplot): higher MAT has higher variance (heteroskedacity)
3. ANPP is not linearly related to MAP.
4. MAP is not normally distributed; it is strictly positive and right-skewed. log(MAP) is much closer to normal.
5. MAT is closer to normally distributed, but it still has a sort of weird shape.
6. We recover a more linear relationship between log(MAP) and ANPP, but variance is still non-constant.
7. There may be regional differences in distribution of MAP, MAT, and ANPP. Especially when it comes to MAT, region may help increase amount of variance explained toward the tail end of the MAT distribution

Taking 1 and 2 together, we should use either a Gamma or Inverse Gaussian distribution as the response distribution.

# Approach to modeling

We want to know:

1. Which distribution? Gamma or inverse gaussian?
2. Which combination of predictors?
  - Include interactions?
  - Transform predictors?
 
Gamma vs Inverse Gaussian: 
https://link.springer.com/chapter/10.1007/978-1-4419-0118-7_11 (found a pdf)
- Gamma has variance related to mean^2
- Inverse gaussian has variance related to mean^3
- We can figure this out by plotting log(variance) against log(means) and seeing whether the slope is closer to 2 or 3.
- Typically use inverse gaussian with really really severe skew, which I don't think we have. There's some code in the graveyard formalizing this, but Gamma is our best bet I think.

Because Gamma is best bet, we can just look at (2). I think we can start with a saturated model and look at leverage. Based on that, transform predictors and see if that helps with leverage. Then start paring down the model.

# Including region

## Full Model

### Running 

Including region, MAT, and MAP with all interactions:

```{r}
m1_rgn <- glm(ANPP ~ MAT*MAP*region,
              family = Gamma(link = 'log'),
              data = anpp_f)

# with log-transformed MAP
m1_rgn_log <- glm(ANPP ~ MAT*log(MAP)*region,
                  family = Gamma(link = 'log'),
                  data = anpp_f)
```



### Diagnostics

First, let's see if log-transforming makes a difference:

```{r}
AIC(m1_rgn, m1_rgn_log)
```
It looks like there is marginal improvement by including the log-transform.

Let's unpack this a little further by looking at diagnostic plots:
```{r}
plot(m1_rgn)
```

It looks like we don't have any super influential points (i.e., points with high Cook's distance). However, there is some weird tail behavior in the Q-Q plot at the upper end. Let's look at the log model:

```{r}
plot(m1_rgn_log)
```

These results look pretty similar to before. Let's compare residuals vs fitted side by side:

```{r}
par(mfrow = c(1, 2))
plot(m1_rgn, which = 1)
plot(m1_rgn_log, which = 1)
```
These also look very similar; some of the tail residuals on either end have been moved a little closer to 0, though.

### ANOVA

Now let's see how we can pare back the log model using ANOVA.

```{r}
anova(m1_rgn_log, test = 'Chisq')
```

This is interesting. Dropping the three-way interaction term leads to a large increase in residual deviance (i.e., the fitted model gets further from the saturated model), but the pairwise interactions don't necessarily have the same effect. Dropping any one of the non-interaction terms leads to a larger increase in residual deviance.

## Simplified model 2

### Running

Let's run our simplified model with the three-way interaction term and the individual terms.

```{r}
m2_rgn_log <- glm(ANPP ~ MAT+log(MAP)+region+MAT:log(MAP):region,
                  family = Gamma(link = 'log'),
                  data = anpp_f)
```

### Diagnostics

First, let's see if this is an improvement over our previous model. 

```{r}
AIC(m1_rgn_log, m2_rgn_log)
```
We actually see that the previous model had a lower AIC, so this model is not necessarily an improvement. Let's look at diagnostic plots:

```{r}
plot(m2_rgn_log)
```


And look at analysis of deviance:

```{r}
anova(m2_rgn_log, test = 'Chisq')
```
We may be able to drop the 3-way interaction term entirely.

## Simplified model 3

### Running the model

Let's try just including the single terms and no interaction:

```{r}
m3_rgn_log <- glm(ANPP ~ MAT+log(MAP)+region,
                  family = Gamma(link = 'log'),
                  data = anpp_f)
```


### Diagnostics

```{r}
AIC(m1_rgn_log, m2_rgn_log, m3_rgn_log)
```

M1 still "wins" with the lowest AIC.

```{r}
plot(m3_rgn_log)
```

From the plots, we see that the residuals vs leverage plot and the scale-location plot actually look worse than the original full model.

```{r}
anova(m3_rgn_log)
```

All our terms have a significant contribution, though.

# Modeling -- no region

Let's ignore region and see what we get.

## Full Model

As always, we'll start by running a full model.
 
### Running the model

```{r}
m1 <- glm(ANPP ~ MAT*MAP,
          family = Gamma(link = 'log'),
          data = anpp)
```
### Diagnostics

```{r}
plot(m1)
```

We have some higher leverage points (but still within acceptable Cook's distance); let's see where these points fall on the distribution of MAT and MAP:

```{r}
#| label: leverage-points

m1_lev <- c(37, 38, 46)
m1_mat_lev <- anpp[m1_lev, 3]
m1_map_lev <- anpp[m1_lev, 4]

hist(anpp$MAT)
abline(v = m1_mat_lev, col = 'red')

hist(anpp$MAP)
abline(v = m1_map_lev, col = 'red')
```

We can see that, in fact, the high leverage points for MAP are on the tail end. So then we can log-transform the MAP data to get it better behaved:

```{r}
#| label: examine-leverage
hist(log(anpp$MAP))
abline(v = log(m1_map_lev), col = 'red')
```


While these points still fall on the tails, they may have less leverage now. Let's check:


```{r}
#| label: full-model-log
m1_log <- glm(ANPP ~ MAT*log(MAP),
                family = Gamma(link = 'log'),
                data = anpp_f)
plot(m1_log)
```

Leverage plot looks a lot better, but residuals are a bit wonky at the tail end of the CDF (Q-Q plot). Let's see if this model fits better than the un-logged one, using AIC:

```{r}
AIC(m1, m1_log)
```

Looks like, as we suspected from residuals, that m1_log is better.

### ANOVA

Let's now look at an analysis of deviance to see if we can pare this model down.

```{r}
anova(m1_log)
```

It looks like no: both terms and their interactions contribute significantly to decreasing the residual deviance. Because these models are nested, we don't even need to use AIC. But just to check, let's run a model that doesn't include the interaction term.

## Simplified Model 2

### Running the model

Let's remove the interaction term. If all is right in the world, our ANOVA and AIC results

```{r}
m2_log <- glm(ANPP ~ log(MAP)+MAT,
              family = Gamma(link = 'log'),
              data = anpp_f)
```

### Diagnostics

```{r}
plot(m2_log)
```

Residuals vs fitted looks a little funky here. Let's use AIC to compare this model to the full model. If all is right in the world, this will have a higher AIC (agreeing with the ANOVA results):

```{r}
AIC(m1_log, m2_log)
```

We do in fact see a higher AIC with this model, as expected.

# Comparing region with no region

Finally, let's compare all our models:

```{r}
AIC(m1_log, 
    m2_log,
    m1_rgn_log,
    m2_rgn_log,
    m3_rgn_log) |>
  arrange(AIC) # arrange in order of increasing AIC
```

The regional model has the lowest AIC, and models that include region out perform all other models.
